{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6I/lpyIY/sBmNL7y540u9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarora18/kaggle-hack-2/blob/main/kaggle_hack_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aFPeYJPqOBW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.decomposition import PCA\n",
        "#from catboost import CatBoostRegressor\n",
        "#from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/kaggle/input/thapar-summer-school-2025-hack-ii/train.csv\")\n",
        "df.head()\n",
        "\n",
        "df = df.drop(columns=[\"id\", \"Row#\"], errors=\"ignore\")\n",
        "df.head()\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.001, random_state=42\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Split training set\n",
        "#X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = LGBMRegressor(\n",
        "    objective='mae',\n",
        "    n_estimators=5000,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=7,\n",
        "    num_leaves=128,\n",
        "    min_child_samples=20,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.5,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model with callback-based early stopping\n",
        "model.fit(\n",
        "    X_tr, y_tr,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric='mae',\n",
        "    callbacks=[early_stopping(100), log_evaluation(100)]\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "y_val_pred = model.predict(X_val)\n",
        "mae = mean_absolute_error(y_val, y_val_pred)\n",
        "print(f\"Validation MAE: {mae:.4f}\")"
      ]
    }
  ]
}